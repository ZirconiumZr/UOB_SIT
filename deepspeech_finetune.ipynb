{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepspeech_finetune.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load training data\n",
        "need upload testdata.csv&sample.zip in /content/\n",
        "\n",
        "Divided into training set and test set"
      ],
      "metadata": {
        "id": "w6cBsw2biunI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IF9URqPndwV5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "file = \"testdata.csv\"\n",
        "\n",
        "df1 = pd.read_csv(file)\n",
        "df1['split'] = np.random.randn(df1.shape[0], 1)\n",
        "# Split ratio for training set\n",
        "msk = np.random.rand(len(df1)) <= 0.5\n",
        "train = df1[msk]\n",
        "inter = df1[~msk]\n",
        "train.to_csv('train.csv', index=False)\n",
        "inter.to_csv('intermediate.csv', index=False)\n",
        "\n",
        "df2 = pd.read_csv('intermediate.csv')\n",
        "df2['split'] = np.random.randn(df2.shape[0], 1)\n",
        "# Split ratio for dev and test\n",
        "msk = np.random.rand(len(df2)) <= 0.5\n",
        "dev = df2[msk]\n",
        "test = df2[~msk]\n",
        "dev.to_csv('dev.csv', index=False)\n",
        "test.to_csv('test.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip sample.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzqMkSVHd083",
        "outputId": "c2f16b4e-8a5a-4819-8d6e-e948c70ea9ca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sample.zip\n",
            "   creating: sample/\n",
            "  inflating: sample/1.wav            \n",
            "  inflating: sample/10.wav           \n",
            "  inflating: sample/11.wav           \n",
            "  inflating: sample/12.wav           \n",
            "  inflating: sample/13.wav           \n",
            "  inflating: sample/14.wav           \n",
            "  inflating: sample/15.wav           \n",
            "  inflating: sample/2.wav            \n",
            "  inflating: sample/3.wav            \n",
            "  inflating: sample/4.wav            \n",
            "  inflating: sample/5.wav            \n",
            "  inflating: sample/6.wav            \n",
            "  inflating: sample/7.wav            \n",
            "  inflating: sample/8.wav            \n",
            "  inflating: sample/9.wav            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load training code"
      ],
      "metadata": {
        "id": "6r9RlZX1jA5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --branch v0.9.3 https://github.com/mozilla/DeepSpeech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghUX3LTteE1Q",
        "outputId": "30692c8b-711c-4d69-f0bd-fc0f445fe3ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepSpeech'...\n",
            "remote: Enumerating objects: 23888, done.\u001b[K\n",
            "remote: Total 23888 (delta 0), reused 0 (delta 0), pack-reused 23888\u001b[K\n",
            "Receiving objects: 100% (23888/23888), 49.36 MiB | 22.85 MiB/s, done.\n",
            "Resolving deltas: 100% (16417/16417), done.\n",
            "Note: checking out 'f2e9c85880dff94115ab510cde9ca4af7ee51c19'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-checkpoint.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4grM8y0eIQp",
        "outputId": "15fcbc34-4516-4858-8b3d-dffb560005c9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-04 10:06:31--  https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-checkpoint.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/60273704/6598e800-3b0f-11eb-9e91-3db57dd0c70b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220404T100631Z&X-Amz-Expires=300&X-Amz-Signature=2a7f773f9583a865611f3e679847ec83bbd47c086a6cf7b7ca883dc4b138da9e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-checkpoint.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-04 10:06:31--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/60273704/6598e800-3b0f-11eb-9e91-3db57dd0c70b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220404T100631Z&X-Amz-Expires=300&X-Amz-Signature=2a7f773f9583a865611f3e679847ec83bbd47c086a6cf7b7ca883dc4b138da9e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-checkpoint.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 645992216 (616M) [application/octet-stream]\n",
            "Saving to: ‘deepspeech-0.9.3-checkpoint.tar.gz’\n",
            "\n",
            "deepspeech-0.9.3-ch 100%[===================>] 616.07M  46.5MB/s    in 14s     \n",
            "\n",
            "2022-04-04 10:06:45 (43.3 MB/s) - ‘deepspeech-0.9.3-checkpoint.tar.gz’ saved [645992216/645992216]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"/content/deepspeech-0.9.3-checkpoint.tar.gz\")\n",
        "names = tar.getnames()\n",
        "for name in names:\n",
        "  tar.extract(name,path=\"/content/\")\n",
        "tar.close()"
      ],
      "metadata": {
        "id": "kp3nJ4gUeL1f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install training dependencies\n",
        "need to restart the runtime after finishing this part and start the next part directly"
      ],
      "metadata": {
        "id": "vlccJG8XjLqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd DeepSpeech\n",
        "!pip install --upgrade pip==20.0.2 wheel==0.34.2 setuptools==46.1.3\n",
        "!pip install --upgrade -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L3k88dP0eQXX",
        "outputId": "8d72bf12-38fc-4336-e51b-d90ced10e4b4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech\n",
            "Collecting pip==20.0.2\n",
            "  Downloading pip-20.0.2-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting wheel==0.34.2\n",
            "  Downloading wheel-0.34.2-py2.py3-none-any.whl (26 kB)\n",
            "Collecting setuptools==46.1.3\n",
            "  Downloading setuptools-46.1.3-py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 44.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: wheel, setuptools, pip\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.37.1\n",
            "    Uninstalling wheel-0.37.1:\n",
            "      Successfully uninstalled wheel-0.37.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "pip-tools 6.2.0 requires pip>=20.3, but you have pip 20.0.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed pip-20.0.2 setuptools-46.1.3 wheel-0.34.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/DeepSpeech\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.21.5)\n",
            "Requirement already satisfied, skipping upgrade: progressbar2 in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (3.38.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.15.0)\n",
            "Collecting pyxdg\n",
            "  Downloading pyxdg-0.27-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting attrdict\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: semver in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (2.13.0)\n",
            "Collecting opuslib==2.0.0\n",
            "  Downloading opuslib-2.0.0.tar.gz (7.3 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 10.1 MB/s \n",
            "\u001b[?25hCollecting sox\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied, skipping upgrade: bs4 in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (0.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.3.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (2.23.0)\n",
            "Collecting numba==0.47.0\n",
            "  Downloading numba-0.47.0-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 49.3 MB/s \n",
            "\u001b[?25hCollecting llvmlite==0.31.0\n",
            "  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 56.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: librosa in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: soundfile in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (0.10.3.post1)\n",
            "Collecting ds_ctcdecoder==0.9.3\n",
            "  Downloading ds_ctcdecoder-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 32.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.4\n",
            "  Downloading tensorflow-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->deepspeech-training==0.9.3) (3.1.0)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 42.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.9.3) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.9.3) (1.4.32)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.9.3) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.9.3) (21.3)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.9.3) (4.63.0)\n",
            "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->deepspeech-training==0.9.3) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepspeech-training==0.9.3) (2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepspeech-training==0.9.3) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->deepspeech-training==0.9.3) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->deepspeech-training==0.9.3) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->deepspeech-training==0.9.3) (2021.10.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->deepspeech-training==0.9.3) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.47.0->deepspeech-training==0.9.3) (46.1.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (2.1.9)\n",
            "Requirement already satisfied, skipping upgrade: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->deepspeech-training==0.9.3) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (3.17.3)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (1.1.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 28.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (1.44.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (0.2.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 47.6 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->deepspeech-training==0.9.3) (3.2.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->deepspeech-training==0.9.3) (3.0.7)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->deepspeech-training==0.9.3) (4.11.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->deepspeech-training==0.9.3) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: greenlet!=0.4.17; python_version >= \"3\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->deepspeech-training==0.9.3) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->deepspeech-training==0.9.3) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->deepspeech-training==0.9.3) (1.4.4)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->deepspeech-training==0.9.3) (2.21)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.9.3) (3.3.6)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.9.3) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4->deepspeech-training==0.9.3) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->deepspeech-training==0.9.3) (21.4.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->deepspeech-training==0.9.3) (3.10.0.2)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->deepspeech-training==0.9.3) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.9\"->alembic->optuna->deepspeech-training==0.9.3) (3.7.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna->deepspeech-training==0.9.3) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.4->deepspeech-training==0.9.3) (1.5.2)\n",
            "Building wheels for collected packages: opuslib, gast, pyperclip\n",
            "  Building wheel for opuslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opuslib: filename=opuslib-2.0.0-py3-none-any.whl size=11009 sha256=9ff18f565f66a92d332a124653dbc765b76b315a48975c8a1e455c2bd9600405\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/ba/d4/0e81231a9797fbb262ae3a54fd761fab850db7f32d94a3283a\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=dbd455548907432d2d06cd08022476acbf7a697b1d366ba5e12895f8c7e85647\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=b95fbcf07e5afff7cffce6987f391b9dcad9cee8ae8d73ea0b223d2b2d9ace4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built opuslib gast pyperclip\n",
            "\u001b[31mERROR: tensorflow 1.15.4 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.21.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.16.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.7 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyxdg, attrdict, opuslib, pyperclip, cmd2, pbr, stevedore, autopage, cliff, Mako, alembic, cmaes, colorlog, optuna, sox, llvmlite, numba, ds-ctcdecoder, tensorflow-estimator, tensorboard, gast, keras-applications, tensorflow, deepspeech-training\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "  Running setup.py develop for deepspeech-training\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 attrdict-2.0.1 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 deepspeech-training ds-ctcdecoder-0.9.3 gast-0.2.2 keras-applications-1.0.8 llvmlite-0.31.0 numba-0.47.0 optuna-2.10.0 opuslib-2.0.0 pbr-5.8.1 pyperclip-1.8.2 pyxdg-0.27 sox-1.4.1 stevedore-3.5.0 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA28T9Yll_vO",
        "outputId": "fc1aa812-f820-49da-8fa4-c78d2e2ef7b7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 1.15.4\n",
            "Uninstalling tensorflow-1.15.4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-1.15.4.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.15.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'tensorflow-gpu==1.15.4'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "id": "V0pqcgYVifHw",
        "outputId": "53c8c104-168b-41f8-def5-d1acaa1a3d43"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu==1.15.4\n",
            "  Downloading tensorflow_gpu-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (411.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.44.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.1.2)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.34.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.15.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.4) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (1.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.4) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.7.0)\n",
            "\u001b[31mERROR: kapre 0.3.7 requires tensorflow>=2.0.0, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: deepspeech-training 0.9.3 requires tensorflow==1.15.4, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.16.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tables 3.7.0 has requirement numpy>=1.19.0, but you'll have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: jaxlib 0.3.2+cuda11.cudnn805 has requirement numpy>=1.19, but you'll have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: jax 0.3.4 has requirement numpy>=1.19, but you'll have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, tensorflow-gpu\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "Successfully installed numpy-1.18.5 tensorflow-gpu-1.15.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cuda\n",
        "\n",
        "no need this part from now"
      ],
      "metadata": {
        "id": "3xqUGMkzutjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! echo $PATH\n",
        "\n",
        "# import os\n",
        "# os.environ['PATH'] += \":/usr/local/cuda-10.0/bin\"\n",
        "# os.environ['CUDADIR'] = \"/usr/local/cuda-10.0\"\n",
        "# os.environ['LD_LIBRARY_PATH'] = \"/usr/lib64-nvidia:/usr/local/cuda-10.0/lib64\"\n",
        "\n",
        "# !echo $PATH\n",
        "# !echo $LD_LIBRARY_PATH\n",
        "# !source ~/.bashrc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EAIDnGZutLz",
        "outputId": "a3e1c4ff-8284-404c-b681-5550c05ff818"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/cuda-10.0/bin\n",
            "/usr/lib64-nvidia:/usr/local/cuda-10.0/lib64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !env | grep -i cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUnBaGfLuwPe",
        "outputId": "1a1b473e-54a4-4635-9f41-b4cc0174b2b0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LD_LIBRARY_PATH=/usr/lib64-nvidia:/usr/local/cuda-10.0/lib64\n",
            "CUDADIR=/usr/local/cuda-10.0\n",
            "LIBRARY_PATH=/usr/local/cuda/lib64/stubs\n",
            "CUDA_VERSION=11.1.1\n",
            "NVIDIA_REQUIRE_CUDA=cuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 brand=tesla,driver>=450,driver<451\n",
            "PATH=/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/cuda-10.0/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/\n",
        "# !wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "# !sudo apt-get install freeglut3 freeglut3-dev libxi-dev libxmu-dev\n",
        "# !sudo apt-get install build-essential dkms\n",
        "# !sudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "# !sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
        "\n",
        "# !sudo apt-get update\n",
        "# !sudo apt-get install cuda-10-0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-pKKGviuyYo",
        "outputId": "bc52b44f-98cf-49d1-d642-fe0212d886c1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2022-04-04 08:40:10--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.20.126\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.20.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2940 (2.9K) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1804_10.0.130-1_amd64.deb’\n",
            "\n",
            "cuda-repo-ubuntu180 100%[===================>]   2.87K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-04 08:40:11 (83.5 MB/s) - ‘cuda-repo-ubuntu1804_10.0.130-1_amd64.deb’ saved [2940/2940]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libxi-dev is already the newest version (2:1.7.9-1).\n",
            "libxi-dev set to manually installed.\n",
            "libxmu-dev is already the newest version (2:1.1.2-2).\n",
            "libxmu-dev set to manually installed.\n",
            "freeglut3 is already the newest version (2.8.1-3).\n",
            "freeglut3 set to manually installed.\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "freeglut3-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "dkms is already the newest version (2.3-3ubuntu9.7).\n",
            "dkms set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Selecting previously unselected package cuda-repo-ubuntu1804.\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1804_10.0.130-1_amd64.deb ...\n",
            "Unpacking cuda-repo-ubuntu1804 (10.0.130-1) ...\n",
            "Setting up cuda-repo-ubuntu1804 (10.0.130-1) ...\n",
            "\n",
            "Configuration file '/etc/apt/sources.list.d/cuda.list'\n",
            " ==> File on system created by you or by a script.\n",
            " ==> File also in package provided by package maintainer.\n",
            "   What would you like to do about it ?  Your options are:\n",
            "    Y or I  : install the package maintainer's version\n",
            "    N or O  : keep your currently-installed version\n",
            "      D     : show the differences between the versions\n",
            "      Z     : start a shell to examine the situation\n",
            " The default action is to keep your current version.\n",
            "*** cuda.list (Y/I/N/O/D/Z) [default=N] ? N\n",
            "Executing: /tmp/apt-key-gpghome.YJzePzRI08/gpg.1.sh --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
            "gpg: requesting key from 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub'\n",
            "gpg: key F60F4B3D7FA2AF80: \"cudatools <cudatools@nvidia.com>\" not changed\n",
            "gpg: Total number processed: 1\n",
            "gpg:              unchanged: 1\n",
            "Get:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:3 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,831 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [82.3 kB]\n",
            "Get:12 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [938 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.3 kB]\n",
            "Ign:16 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:18 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [884 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [918 kB]\n",
            "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [950 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,693 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,264 kB]\n",
            "Get:26 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,486 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,132 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.9 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n",
            "Fetched 15.6 MB in 2s (6,420 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 95 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo rm /usr/local/cuda\n",
        "# !sudo ln -s /usr/local/cuda-10.0 /usr/local/cuda\n",
        "# %ls -l /usr/local/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvkbLkwxu-6Z",
        "outputId": "ff455816-0622-43a4-f0b7-838eebf5097c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 68\n",
            "drwxr-xr-x  1 root root 4096 Apr  4 08:05 \u001b[0m\u001b[01;34mbin\u001b[0m/\n",
            "lrwxrwxrwx  1 root root   20 Apr  4 08:41 \u001b[01;36mcuda\u001b[0m -> \u001b[01;34m/usr/local/cuda-10.0\u001b[0m/\n",
            "drwxr-xr-x 16 root root 4096 Mar 23 14:05 \u001b[01;34mcuda-10.0\u001b[0m/\n",
            "drwxr-xr-x 15 root root 4096 Mar 23 14:07 \u001b[01;34mcuda-10.1\u001b[0m/\n",
            "lrwxrwxrwx  1 root root   25 Mar 23 14:13 \u001b[01;36mcuda-11\u001b[0m -> \u001b[01;34m/etc/alternatives/cuda-11\u001b[0m/\n",
            "drwxr-xr-x 15 root root 4096 Mar 23 14:10 \u001b[01;34mcuda-11.0\u001b[0m/\n",
            "drwxr-xr-x  1 root root 4096 Mar 23 14:12 \u001b[01;34mcuda-11.1\u001b[0m/\n",
            "drwxr-xr-x  1 root root 4096 Mar 23 14:23 \u001b[01;34metc\u001b[0m/\n",
            "drwxr-xr-x  2 root root 4096 Nov 19  2020 \u001b[01;34mgames\u001b[0m/\n",
            "drwxr-xr-x  2 root root 4096 Mar 23 14:32 \u001b[01;34m_gcs_config_ops.so\u001b[0m/\n",
            "drwxr-xr-x  1 root root 4096 Mar 23 14:31 \u001b[01;34minclude\u001b[0m/\n",
            "drwxr-xr-x  1 root root 4096 Mar 23 14:32 \u001b[01;34mlib\u001b[0m/\n",
            "drwxr-xr-x  3 root root 4096 Mar 23 14:31 \u001b[01;34mlicensing\u001b[0m/\n",
            "lrwxrwxrwx  1 root root    9 Nov 19  2020 \u001b[01;36mman\u001b[0m -> \u001b[01;34mshare/man\u001b[0m/\n",
            "drwxr-xr-x  2 root root 4096 Nov 19  2020 \u001b[01;34msbin\u001b[0m/\n",
            "drwxr-xr-x  1 root root 4096 Mar 23 14:30 \u001b[01;34mshare\u001b[0m/\n",
            "drwxr-xr-x  2 root root 4096 Nov 19  2020 \u001b[01;34msrc\u001b[0m/\n",
            "drwxr-xr-x  2 root root 4096 Mar 23 14:31 \u001b[01;34mxgboost\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "a4aYkxcFjXwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd DeepSpeech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo-LfTODfn__",
        "outputId": "cf62dcde-9907-4545-bee5-5ca8901f1bfc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python DeepSpeech.py --train_cudnn True --n_hidden 2048 --checkpoint_dir /content/deepspeech-0.9.3-checkpoint --epochs 3 --train_files /content/train.csv --dev_files /content/dev.csv --test_files /content/test.csv --learning_rate 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mryKqx-TfB37",
        "outputId": "c7013265-f5b7-4dae-9d84-c4ba4642c811"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I Loading best validating checkpoint from /content/deepspeech-0.9.3-checkpoint/best_dev-1466493\n",
            "I Loading variable from checkpoint: beta1_power\n",
            "I Loading variable from checkpoint: beta2_power\n",
            "I Loading variable from checkpoint: cudnn_lstm/opaque_kernel\n",
            "I Loading variable from checkpoint: cudnn_lstm/opaque_kernel/Adam\n",
            "I Loading variable from checkpoint: cudnn_lstm/opaque_kernel/Adam_1\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/bias/Adam\n",
            "I Loading variable from checkpoint: layer_6/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "I Loading variable from checkpoint: layer_6/weights/Adam\n",
            "I Loading variable from checkpoint: layer_6/weights/Adam_1\n",
            "I Loading variable from checkpoint: learning_rate\n",
            "I STARTING Optimization\n",
            "Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 6 | Loss: 109.968849      \n",
            "Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 6 | Loss: 82.433164 | Dataset: /content/dev.csv\n",
            "I Saved new best validating model with loss 82.433164 to: /content/deepspeech-0.9.3-checkpoint/best_dev-1466499\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1 |   Training | Elapsed Time: 0:00:04 | Steps: 6 | Loss: 92.502405       \n",
            "Epoch 1 | Validation | Elapsed Time: 0:00:01 | Steps: 6 | Loss: 82.400959 | Dataset: /content/dev.csv\n",
            "I Saved new best validating model with loss 82.400959 to: /content/deepspeech-0.9.3-checkpoint/best_dev-1466505\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2 |   Training | Elapsed Time: 0:00:04 | Steps: 6 | Loss: 80.004393       \n",
            "Epoch 2 | Validation | Elapsed Time: 0:00:01 | Steps: 6 | Loss: 82.570331 | Dataset: /content/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "I FINISHED optimization in 0:00:33.443546\n",
            "I Loading best validating checkpoint from /content/deepspeech-0.9.3-checkpoint/best_dev-1466505\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "Testing model on /content/test.csv\n",
            "Test epoch | Steps: 3 | Elapsed Time: 0:00:15                                   \n",
            "Test on /content/test.csv - WER: 0.538462, CER: 0.261261, loss: 95.245415\n",
            "--------------------------------------------------------------------------------\n",
            "Best WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.444444, CER: 0.267327, loss: 95.769218\n",
            " - wav: file:///content/sample/13.wav\n",
            " - src: \"this is a copy of our specimen contract in which the general sales terms and conditions are contained\"\n",
            " - res: \"this is a colpy of ours business puntract in lage the general self terms and the conditions are comtentd\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.571429, CER: 0.292929, loss: 84.925987\n",
            " - wav: file:///content/sample/11.wav\n",
            " - src: \"we had better draw up a rough draft to the contract then talk it over in detail at our next meeting\"\n",
            " - res: \"late by ter dra up a rash dreadt to the countract the tuc aid hour in detail at our liges meeting\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.576923, CER: 0.233083, loss: 105.041039\n",
            " - wav: file:///content/sample/5.wav\n",
            " - src: \"hi there payment is against the wrong card for my upcoming trip it should be taken from the mastercard on my account and not the visa\"\n",
            " - res: \"hi there pen my ic o gan ste wrong cotk for my hopcoming trip he shuld be taken from the master cot o my count and not the wesa\"\n",
            "--------------------------------------------------------------------------------\n",
            "Median WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.576923, CER: 0.233083, loss: 105.041039\n",
            " - wav: file:///content/sample/5.wav\n",
            " - src: \"hi there payment is against the wrong card for my upcoming trip it should be taken from the mastercard on my account and not the visa\"\n",
            " - res: \"hi there pen my ic o gan ste wrong cotk for my hopcoming trip he shuld be taken from the master cot o my count and not the wesa\"\n",
            "--------------------------------------------------------------------------------\n",
            "Worst WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.444444, CER: 0.267327, loss: 95.769218\n",
            " - wav: file:///content/sample/13.wav\n",
            " - src: \"this is a copy of our specimen contract in which the general sales terms and conditions are contained\"\n",
            " - res: \"this is a colpy of ours business puntract in lage the general self terms and the conditions are comtentd\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.571429, CER: 0.292929, loss: 84.925987\n",
            " - wav: file:///content/sample/11.wav\n",
            " - src: \"we had better draw up a rough draft to the contract then talk it over in detail at our next meeting\"\n",
            " - res: \"late by ter dra up a rash dreadt to the countract the tuc aid hour in detail at our liges meeting\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.576923, CER: 0.233083, loss: 105.041039\n",
            " - wav: file:///content/sample/5.wav\n",
            " - src: \"hi there payment is against the wrong card for my upcoming trip it should be taken from the mastercard on my account and not the visa\"\n",
            " - res: \"hi there pen my ic o gan ste wrong cotk for my hopcoming trip he shuld be taken from the master cot o my count and not the wesa\"\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters can be adjusted\n",
        "!python DeepSpeech.py --train_cudnn True --early_stop True --es_epochs 6 --n_hidden 2048 --epochs 30 \\\n",
        "  --export_dir /content/models/ --checkpoint_dir /content/deepspeech-0.9.3-checkpoint \\\n",
        "  --train_files /content/train.csv --dev_files /content/dev.csv --test_files /content/test.csv \\\n",
        "  --learning_rate 0.0001 --train_batch_size 64 --test_batch_size 32 --dev_batch_size 32 --export_file_name 'ft_model' \\\n",
        "  --augment reverb[p=0.2,delay=50.0~30.0,decay=10.0:2.0~1.0] \\\n",
        "  --augment volume[p=0.2,dbfs=-10:-40] \\\n",
        "  --augment pitch[p=0.2,pitch=1~0.2] \\\n",
        "  --augment tempo[p=0.2,factor=1~0.5] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiaAmfpeoktL",
        "outputId": "c2f5cc05-7d78-4091-91a2-4c0addaa90ab"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I Loading best validating checkpoint from /content/deepspeech-0.9.3-checkpoint/best_dev-1466505\n",
            "I Loading variable from checkpoint: beta1_power\n",
            "I Loading variable from checkpoint: beta2_power\n",
            "I Loading variable from checkpoint: cudnn_lstm/opaque_kernel\n",
            "I Loading variable from checkpoint: cudnn_lstm/opaque_kernel/Adam\n",
            "I Loading variable from checkpoint: cudnn_lstm/opaque_kernel/Adam_1\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/bias/Adam\n",
            "I Loading variable from checkpoint: layer_6/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "I Loading variable from checkpoint: layer_6/weights/Adam\n",
            "I Loading variable from checkpoint: layer_6/weights/Adam_1\n",
            "I Loading variable from checkpoint: learning_rate\n",
            "I STARTING Optimization\n",
            "Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000        \n",
            "Epoch 0 | Validation | Elapsed Time: 0:00:01 | Steps: 1 | Loss: 82.400986 | Dataset: /content/dev.csv\n",
            "I Saved new best validating model with loss 82.400986 to: /content/deepspeech-0.9.3-checkpoint/best_dev-1466505\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000        \n",
            "Epoch 1 | Validation | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 82.400986 | Dataset: /content/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000        \n",
            "Epoch 2 | Validation | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 82.400986 | Dataset: /content/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000        \n",
            "Epoch 3 | Validation | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 82.400986 | Dataset: /content/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000        \n",
            "Epoch 4 | Validation | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 82.400986 | Dataset: /content/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000        \n",
            "Epoch 5 | Validation | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 82.400986 | Dataset: /content/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000        \n",
            "Epoch 6 | Validation | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 82.400986 | Dataset: /content/dev.csv\n",
            "I Early stop triggered as the loss did not improve the last 6 epochs\n",
            "I FINISHED optimization in 0:00:31.929461\n",
            "I Loading best validating checkpoint from /content/deepspeech-0.9.3-checkpoint/best_dev-1466505\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "Testing model on /content/test.csv\n",
            "Test epoch | Steps: 1 | Elapsed Time: 0:00:16                                   \n",
            "Test on /content/test.csv - WER: 0.538462, CER: 0.261261, loss: 95.245422\n",
            "--------------------------------------------------------------------------------\n",
            "Best WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.444444, CER: 0.267327, loss: 95.769257\n",
            " - wav: file:///content/sample/13.wav\n",
            " - src: \"this is a copy of our specimen contract in which the general sales terms and conditions are contained\"\n",
            " - res: \"this is a colpy of ours business puntract in lage the general self terms and the conditions are comtentd\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.571429, CER: 0.292929, loss: 84.925987\n",
            " - wav: file:///content/sample/11.wav\n",
            " - src: \"we had better draw up a rough draft to the contract then talk it over in detail at our next meeting\"\n",
            " - res: \"late by ter dra up a rash dreadt to the countract the tuc aid hour in detail at our liges meeting\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.576923, CER: 0.233083, loss: 105.041031\n",
            " - wav: file:///content/sample/5.wav\n",
            " - src: \"hi there payment is against the wrong card for my upcoming trip it should be taken from the mastercard on my account and not the visa\"\n",
            " - res: \"hi there pen my ic o gan ste wrong cotk for my hopcoming trip he shuld be taken from the master cot o my count and not the wesa\"\n",
            "--------------------------------------------------------------------------------\n",
            "Median WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.576923, CER: 0.233083, loss: 105.041031\n",
            " - wav: file:///content/sample/5.wav\n",
            " - src: \"hi there payment is against the wrong card for my upcoming trip it should be taken from the mastercard on my account and not the visa\"\n",
            " - res: \"hi there pen my ic o gan ste wrong cotk for my hopcoming trip he shuld be taken from the master cot o my count and not the wesa\"\n",
            "--------------------------------------------------------------------------------\n",
            "Worst WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.444444, CER: 0.267327, loss: 95.769257\n",
            " - wav: file:///content/sample/13.wav\n",
            " - src: \"this is a copy of our specimen contract in which the general sales terms and conditions are contained\"\n",
            " - res: \"this is a colpy of ours business puntract in lage the general self terms and the conditions are comtentd\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.571429, CER: 0.292929, loss: 84.925987\n",
            " - wav: file:///content/sample/11.wav\n",
            " - src: \"we had better draw up a rough draft to the contract then talk it over in detail at our next meeting\"\n",
            " - res: \"late by ter dra up a rash dreadt to the countract the tuc aid hour in detail at our liges meeting\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.576923, CER: 0.233083, loss: 105.041031\n",
            " - wav: file:///content/sample/5.wav\n",
            " - src: \"hi there payment is against the wrong card for my upcoming trip it should be taken from the mastercard on my account and not the visa\"\n",
            " - res: \"hi there pen my ic o gan ste wrong cotk for my hopcoming trip he shuld be taken from the master cot o my count and not the wesa\"\n",
            "--------------------------------------------------------------------------------\n",
            "I Exporting the model...\n",
            "I Loading best validating checkpoint from /content/deepspeech-0.9.3-checkpoint/best_dev-1466505\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "I Models exported at /content/models/\n",
            "I Model metadata file saved to /content/models/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# export new model"
      ],
      "metadata": {
        "id": "_uNc_DbFPWWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/DeepSpeech/\n",
        "!python util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmlolnS6pKuc",
        "outputId": "8f96268a-ee64-474c-ca2c-c427b1f1bbe7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech\n",
            "Downloading https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.tensorflow.pip.r1.15.cpu/artifacts/public/convert_graphdef_memmapped_format ...\n",
            "Downloading: 100%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./convert_graphdef_memmapped_format --in_graph=/content/models/ft_model.pb --out_graph=/content/models/ft_model.pbmm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsyATpTsq3kW",
        "outputId": "003a8b57-9a41-43a6-fee0-e8ad2412f4cd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-04 11:03:29.671392: I tensorflow/contrib/util/convert_graphdef_memmapped_format_lib.cc:171] Converted 7 nodes\n"
          ]
        }
      ]
    }
  ]
}