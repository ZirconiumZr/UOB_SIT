# -*- coding: utf-8 -*-
"""Labelling_w2vtrainmodel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SaNonUdXbEc5YCPkPg3i3UApsBxf4mVy
"""

from gensim.models import Word2Vec

import nltk
from nltk import word_tokenize
try:
  nltk.data.find('tokenizers/punkt')
except LookupError:
  nltk.download('punkt')
stop_words = 'nan'

# training data preparation
def preprocess(doc):
    doc = str(doc).lower()  # Lower the text.
    doc = word_tokenize(doc)  # Split into words.
    doc = [w for w in doc if not w in stop_words]  # Remove stopwords.
    doc = [w for w in doc if w.isalpha()]  # Remove numbers and punctuation.
    return doc

w2v_corpus=[]

with open("checklist.txt", "r", encoding='UTF-8') as f:
    for line in f.readlines():
        line = line.strip('\n')
        line = preprocess(line)
        w2v_corpus.append(line)

# training
model = Word2Vec(w2v_corpus, min_count=1)
print("Model trained successfully")

# save model
model.save("new_label_wordvector_model")
print("Model saved successfully")

# load model
# new_model = Word2Vec.load("new_label_wordvector_model")

# retrain model
# text = "hello, how are you"
# text = preprocess(text)
# new_model.train(text, total_examples=model.corpus_count, epochs=10)
